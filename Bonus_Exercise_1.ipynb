{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saputoa21/ADS_2024_Saputoa/blob/master/Bonus_Exercise_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bonus Exercises 1: Aligning Multilingual Embedding Spaces**\n",
        "\n",
        "\n",
        "\n",
        "This notebook represents the first bonus exercises for the lecture Multilingual and Crosslingual Methods and Language Resources (2024W 340168-1). For each successfully completed bonus exercise, a maximum of three points can be achieved that will be added to the points of the final exam. The tasks to be completed in the following notebook are marked with ðŸ‘‹ âš’.\n"
      ],
      "metadata": {
        "id": "H_RsHNVC57Tf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this notebook, you will perform and evaluate a supervised method for aligning the embedding spaces of two languages. The examples in the notebook rely on the language pair English-German, however, feel free to change this pair to languages of your choice from the available embeddings and dictionaries (see below)."
      ],
      "metadata": {
        "id": "UADeK6Y-6Zk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------\n",
        "## **Preparing the Embeddings and Data**\n",
        "\n",
        "In this notebook, we will be using fastText embeddings that represents a character-based version of the word2vec skipgram method. Details on the method can be found in the [original publication](https://aclanthology.org/Q17-1010.pdf) and [this website](https://fasttext.cc/).\n",
        "\n",
        "Pretrained fastText embeddings are available in [157 languages](https://fasttext.cc/docs/en/crawl-vectors.html). The following code cell loads the fastText embeddings for English and German.\n",
        "\n",
        "ðŸ‘‹ âš’ Please change the following download command if you wish to align other languages than English and German.\n",
        "\n",
        "Before you decide on a final language pair, please make sure that:\n",
        "1.   There are pretrained embeddings for this language (see [here](https://fasttext.cc/docs/en/crawl-vectors.html))\n",
        "2.   There is a bilingual word list available (see the [MUSE GitHub](https://github.com/facebookresearch/MUSE/tree/main) section \"Ground-truth bilingual dictionaries\")\n",
        "\n",
        "If the embeddings are available, change the two-digit ISO code in `cc.en.300.vec.g` and `cc.de.300.vec.gz` to the language(s) of your choice."
      ],
      "metadata": {
        "id": "lmoyUnpZKmma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz  # English\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.de.300.vec.gz  # German"
      ],
      "metadata": {
        "id": "DkTFQP9X-IU5",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df98113-19f5-4450-f55c-5e36b9c08c11"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-22 14:28:03--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.238.176.115, 18.238.176.19, 18.238.176.126, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.238.176.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1325960915 (1.2G) [binary/octet-stream]\n",
            "Saving to: â€˜cc.en.300.vec.gzâ€™\n",
            "\n",
            "cc.en.300.vec.gz    100%[===================>]   1.23G   134MB/s    in 11s     \n",
            "\n",
            "2025-01-22 14:28:14 (116 MB/s) - â€˜cc.en.300.vec.gzâ€™ saved [1325960915/1325960915]\n",
            "\n",
            "--2025-01-22 14:28:14--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.de.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.238.176.115, 18.238.176.19, 18.238.176.126, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.238.176.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1278030050 (1.2G) [binary/octet-stream]\n",
            "Saving to: â€˜cc.de.300.vec.gzâ€™\n",
            "\n",
            "cc.de.300.vec.gz    100%[===================>]   1.19G  15.3MB/s    in 15s     \n",
            "\n",
            "2025-01-22 14:28:29 (83.8 MB/s) - â€˜cc.de.300.vec.gzâ€™ saved [1278030050/1278030050]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Embeddings\n",
        "\n",
        "As a next step we will unzip and load the embeddings. For this alignment task, we will only use the top 100,000 words for both languages to speed up the processing. This choice of only using the top 100,000 words also depends on the lenght of the available bilingual word lists."
      ],
      "metadata": {
        "id": "r9LI8R2Q9bPQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HQFF13y09xgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c28e7b3-7fb0-42dc-f4eb-4f7542ecbd20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 100000 English embeddings\n",
            "Loaded 100000 German embeddings\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "\n",
        "def load_fasttext_embeddings(file_path, top_n):\n",
        "    embeddings = {}\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            # Line 0 is a header line\n",
        "            if i > 0 and i <= top_n:\n",
        "              tokens = line.decode('utf-8').strip().split(' ')\n",
        "              word = tokens[0]\n",
        "              vector = np.array(tokens[1:], dtype=np.float32)\n",
        "              vector = vector / np.linalg.norm(vector)\n",
        "              embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "# Load the top English and German embeddings for the top 100,000 words (100000)\n",
        "# FastText sorts the embeddings by decreasing order of word frequency by default\n",
        "en_embeddings = load_fasttext_embeddings('cc.en.300.vec.gz', 100000)\n",
        "de_embeddings = load_fasttext_embeddings('cc.de.300.vec.gz', 100000)\n",
        "\n",
        "print(f\"Loaded {len(en_embeddings)} English embeddings\")\n",
        "print(f\"Loaded {len(de_embeddings)} German embeddings\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us explore the format of the downloaded and loaded embeddings."
      ],
      "metadata": {
        "id": "yhaTWGHKEr1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The loaded embeddings represent a {type(en_embeddings)} datatype.\\n')\n",
        "print(f'Each entry represents the word and the related embedding.\\n')\n",
        "print(f'We can query the word as a key and obtain the embedding, e.g. for good the embedding is {en_embeddings[\"good\"]}.\\n')\n",
        "print(f'The dimensionality of these embeddings corresponds to {len(en_embeddings[\"good\"])}.')"
      ],
      "metadata": {
        "id": "Xb5dngocEwxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59ecf4c-1066-4c7a-9790-e94a88551a92"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The loaded embeddings represent a <class 'dict'> datatype.\n",
            "\n",
            "Each entry represents the word and the related embedding.\n",
            "\n",
            "We can query the word as a key and obtain the embedding, e.g. for good the embedding is [-0.08404064 -0.05785208  0.00155124  0.1233691  -0.05985956  0.00565746\n",
            "  0.11506542 -0.01505614  0.01587738 -0.00118624 -0.0886031   0.02126109\n",
            "  0.00912493  0.00419747  0.01450865  0.0062962   0.07829193 -0.01815862\n",
            " -0.0549321  -0.02126109  0.01076742  0.07500695  0.01359615  0.00821244\n",
            "  0.00638745 -0.05867332  0.03056853 -0.01916236  0.0617758   0.0275573\n",
            "  0.06569952 -0.05192087 -0.03987596  0.00583996  0.04005846  0.05520585\n",
            " -0.00556621 -0.11187168 -0.03221102 -0.02463732 -0.01879736  0.0068437\n",
            " -0.0062962   0.03312351 -0.03020353  0.05292461  0.00757369 -0.05785208\n",
            " -0.05274212  0.00994618 -0.08440564  0.0142349  -0.03722973  0.00611371\n",
            " -0.05812582  0.05365461  0.06579077 -0.04918339 -0.13377152 -0.03695598\n",
            " -0.02290358 -0.04516842 -0.04763215 -0.06250579  0.04261344  0.00419747\n",
            " -0.0686195   0.03312351 -0.06369203  0.01596863 -0.03129852 -0.03941971\n",
            "  0.00693495  0.05192087  0.00583996 -0.00985493  0.02126109  0.06341828\n",
            "  0.04900089  0.02308608  0.03932846 -0.03011228 -0.01158867  0.02627981\n",
            "  0.01049367 -0.02764855  0.02564106  0.08449689  0.08130316  0.2001098\n",
            "  0.03503975  0.04580717  0.12519409 -0.00784744 -0.01040242  0.09708929\n",
            " -0.07199573  0.07327322 -0.00401497 -0.04443843  0.00164249  0.06095456\n",
            "  0.00912493  0.02746605 -0.02728355  0.02290358 -0.03951096 -0.00547496\n",
            " -0.00301123 -0.0477234  -0.02992978  0.10959045  0.01067617 -0.03148102\n",
            "  0.01742862 -0.01149742 -0.01852362  0.01706363  0.04580717  0.05109963\n",
            "  0.04535092  0.03284976 -0.0062962   0.05228587  0.05429336  0.02381608\n",
            "  0.01578614 -0.0064787  -0.11816789  0.01459989  0.00136874 -0.03312351\n",
            " -0.00428872  0.02025735 -0.00638745 -0.02637106  0.03567849  0.03659099\n",
            " -0.03595224 -0.02418107 -0.04306969  0.02436357  0.06834576  0.02865229\n",
            " -0.06414828 -0.03868972 -0.18742613 -0.0828544  -0.01021993  0.05036963\n",
            " -0.10876921  0.0072087  -0.1226391  -0.01359615 -0.01907111  0.08449689\n",
            "  0.05739583 -0.02007485 -0.03339726  0.02363358  0.0408797  -0.01177116\n",
            " -0.03193727 -0.02244734 -0.04334343  0.00118624  0.01049367 -0.00483621\n",
            "  0.10183425  0.02317733 -0.03321476 -0.05411086 -0.00501871  0.0068437\n",
            " -0.01177116 -0.06560828 -0.02272109 -0.04334343  0.00173374 -0.10411549\n",
            "  0.01505614  0.04635466 -0.02445482 -0.04352593  0.00474497  0.03741223\n",
            "  0.02472857 -0.05940332 -0.06068081 -0.07281698  0.04489467  0.04909214\n",
            "  0.01834112 -0.03467475 -0.02290358  0.00374122 -0.04115345 -0.04297844\n",
            " -0.00510996  0.11926289 -0.08714312  0.15156515  0.02025735 -0.05374586\n",
            " -0.01943611  0.00392372 -0.05055213 -0.05739583 -0.04982214  0.10594048\n",
            "  0.11351417 -0.00675245  0.01605988 -0.00693495 -0.05128213 -0.01532989\n",
            "  0.07281698 -0.03695598  0.06579077  0.12154412  0.06487828 -0.0131399\n",
            "  0.02335983  0.05192087 -0.00830369 -0.00574871  0.03330601  0.0062962\n",
            "  0.0406972   0.01678988  0.00200749 -0.01907111  0.07208697 -0.05119088\n",
            "  0.02317733 -0.08823811 -0.03357976  0.01487364  0.00830369 -0.05602709\n",
            "  0.04982214 -0.03513099  0.0275573  -0.12930031  0.15631011 -0.04963964\n",
            " -0.00985493  0.04279594 -0.02637106 -0.02491107  0.08887686 -0.12245662\n",
            " -0.01843237 -0.04325218 -0.02956478  0.00492746 -0.03960221 -0.00027375\n",
            "  0.15348138  0.02837854 -0.0279223  -0.00045625  0.04279594  0.102838\n",
            " -0.12519409  0.05237712  0.00729995 -0.1581351   0.02783105 -0.11570416\n",
            " -0.05538835 -0.03503975 -0.01587738  0.11223669 -0.04854465 -0.06944074\n",
            "  0.01943611  0.01113242 -0.01177116  0.07017074 -0.24427445  0.04854465\n",
            " -0.11506542 -0.02564106  0.07281698 -0.02664481 -0.01615113 -0.09444306\n",
            " -0.04297844 -0.02764855  0.07792693  0.02673606 -0.10210801 -0.00127749\n",
            "  0.0345835   0.02226484 -0.01277491  0.12920906 -0.04671966 -0.08084691].\n",
            "\n",
            "The dimensionality of these embeddings corresponds to 300.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading and Loading the Bilingual Word List\n",
        "\n",
        "To perform this alignment, we will use a bilingual word list that is provided by the Multilingual Unsupervised and Supervised Embeddings (MUSE) project (see [here](https://github.com/facebookresearch/MUSE/tree/main) for all languages).\n",
        "\n",
        "ðŸ‘‹ âš’ Please change the following downloading command to the language pair of your choice (as long as available on MUSE).\n"
      ],
      "metadata": {
        "id": "0TBkmAvzAbyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/arrival/dictionaries/en-de.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "er7DPSxbgP4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d3d24cb-4cc7-4c6d-ffd8-2f920355a68b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-22 14:30:04--  https://dl.fbaipublicfiles.com/arrival/dictionaries/en-de.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.171.22.118, 3.171.22.33, 3.171.22.68, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.171.22.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1742131 (1.7M) [text/x-c++]\n",
            "Saving to: â€˜en-de.txtâ€™\n",
            "\n",
            "en-de.txt           100%[===================>]   1.66M  5.88MB/s    in 0.3s    \n",
            "\n",
            "2025-01-22 14:30:05 (5.88 MB/s) - â€˜en-de.txtâ€™ saved [1742131/1742131]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a bilingual word list\n",
        "\n",
        "As a next step, we will create a bilingual word list from the donwloaded text file.\n",
        "\n",
        "ðŸ‘‹ âš’ Create a list of tuples `[(en_word1, de_word1), (en_word2, de_word2),...]`from the downloaded text file in the following code cell. To complete this task, please complement the provided function `load_bilingual_word_list` where it says `Your code here`.\n",
        "\n",
        "For English-German, the first ten tuples of the list look like this:\n",
        "\n",
        "```\n",
        "[('the', 'die'), ('the', 'der'), ('the', 'dem'), ('the', 'den'), ('the', 'das'), ('and', 'sowie'), ('and', 'und'), ('was', 'war'), ('was', 'wurde'), ('for', 'fÃ¼r')]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "UT-WD8SmAvkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create a list of tuples that contain word translations\n",
        "\n",
        "Parameters:\n",
        "Text file with one bilingual word pair per line\n",
        "\n",
        "Returns:\n",
        "A list of tuples that each contains one bilingual word pair\n",
        "'''\n",
        "def load_bilingual_word_list(file_path):\n",
        "    bilingual_dict = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "      # Your code here\n",
        "      for line in f:\n",
        "          tokens = str(line).strip().split(' ')\n",
        "          en_word = tokens[0]\n",
        "          de_word = tokens[1]\n",
        "          word_pair = (en_word, de_word)\n",
        "          bilingual_dict.append(word_pair)\n",
        "    return bilingual_dict\n",
        "\n",
        "# Load English-German word pairs\n",
        "en_de_pairs = load_bilingual_word_list('en-de.txt')\n",
        "\n",
        "print(en_de_pairs[:10])"
      ],
      "metadata": {
        "id": "snp8ndm5gZEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ce6db8-80eb-48d7-d6ab-40a360086345"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 'die'), ('the', 'der'), ('the', 'dem'), ('the', 'den'), ('the', 'das'), ('and', 'sowie'), ('and', 'und'), ('was', 'war'), ('was', 'wurde'), ('for', 'fÃ¼r')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the Embeddings for our Word List\n",
        "\n",
        "As a next step, we need to see which words from the word list have a vector representation in the embedding space for both languages and create a list of corresponding embeddings for both languages.\n"
      ],
      "metadata": {
        "id": "wCujQTNRLHFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "'''\n",
        "Function to create a list of word embeddings that is parallel to a bilingual list of words\n",
        "\n",
        "Parameters:\n",
        "Bilingual list of words, embeddings in the first language, embeddings in the second language\n",
        "\n",
        "Returns:\n",
        "Two numpy arrays of embeddings that correspond two the bilingual word list\n",
        "'''\n",
        "def extract_word_embeddings(bilingual_pairs, en_embeddings, de_embeddings):\n",
        "    en_vecs = []\n",
        "    de_vecs = []\n",
        "\n",
        "    for en_word, de_word in bilingual_pairs:\n",
        "        if en_word in en_embeddings and de_word in de_embeddings:\n",
        "            en_vecs.append(en_embeddings[en_word])\n",
        "            de_vecs.append(de_embeddings[de_word])\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    en_vecs = np.array(en_vecs)\n",
        "    de_vecs = np.array(de_vecs)\n",
        "\n",
        "    return en_vecs, de_vecs\n",
        "\n",
        "# Extract English and German embeddings for the bilingual lexicon\n",
        "en_vecs, de_vecs = extract_word_embeddings(en_de_pairs, en_embeddings, de_embeddings)\n",
        "\n",
        "print(f\"Extracted {en_vecs.shape[0]} aligned word vectors in English.\")\n",
        "print(f\"Extracted {de_vecs.shape[0]} aligned word vectors in German.\\n\")\n",
        "\n",
        "print(de_vecs[0],\"\\n\")\n",
        "print(len(de_vecs[0]))"
      ],
      "metadata": {
        "id": "ei3DaO3mgnX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120c4340-30f0-48db-870b-fde10f979816"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 22546 aligned word vectors in English.\n",
            "Extracted 22546 aligned word vectors in German.\n",
            "\n",
            "[-5.72045334e-03  1.09642027e-02  9.52727944e-02 -2.60144435e-02\n",
            " -2.86022667e-03  1.80534795e-01  2.54015401e-02  3.55485342e-02\n",
            "  6.81006350e-03 -9.54089984e-02 -1.16452100e-02 -5.85665507e-03\n",
            " -6.66705295e-02 -2.73083560e-02  8.17207620e-03 -1.15771091e-03\n",
            " -3.94983683e-03 -9.94269364e-03  1.40968319e-02 -6.12905715e-04\n",
            "  5.92475571e-03 -3.13262939e-02  6.81006408e-04  7.20504746e-02\n",
            " -4.89643589e-02  1.15771091e-03  8.64878111e-03 -3.07814889e-02\n",
            " -2.79212627e-03 -8.80541205e-02  4.79428507e-02 -2.42438260e-02\n",
            " -3.42546217e-02 -1.54111743e-01  7.49107043e-04  8.98928382e-03\n",
            " -4.69894381e-03  7.30038807e-02  1.37699485e-01 -1.71613600e-02\n",
            " -6.12905715e-04 -1.25305178e-02 -3.51399295e-02 -4.28353027e-02\n",
            " -4.42654174e-03  6.50361106e-02  8.85308348e-03  2.60144435e-02\n",
            "  1.28710205e-02 -2.56807506e-01  4.76704445e-04 -1.54588455e-02\n",
            " -5.24374889e-03 -2.99642817e-03 -3.38460170e-02  4.33801040e-02\n",
            " -4.15413873e-03 -1.12366052e-02 -2.11792979e-02  7.72942230e-02\n",
            " -1.92043800e-02 -5.44805126e-03 -5.42081073e-02  1.22581143e-03\n",
            " -1.62079521e-02  2.45162286e-03  9.79287177e-02  3.57528329e-02\n",
            "  3.56847346e-02 -3.26883071e-03  5.00539690e-02 -4.15413901e-02\n",
            " -1.11004040e-02  2.61506457e-02  9.94269364e-03 -1.58674475e-02\n",
            " -2.72402563e-03 -3.94983683e-03 -3.05771865e-02 -5.17564872e-03\n",
            " -6.87816413e-03 -1.56631472e-03 -1.90681778e-03  1.00244142e-01\n",
            " -4.49464191e-03  2.04301905e-03 -1.66846551e-02 -1.53907444e-02\n",
            "  1.34158256e-02  2.41757277e-02  2.49929354e-01  1.71273112e-01\n",
            " -4.08603810e-02  6.45594075e-02 -1.85233746e-02  2.72402563e-03\n",
            "  3.20072984e-03  3.01685836e-02  1.47437885e-01  4.22223983e-03\n",
            "  1.78423673e-02  3.40503204e-04 -7.49107031e-03  8.71688128e-03\n",
            "  6.53766096e-02 -5.31184953e-03  2.47886330e-02  1.14409067e-02\n",
            " -4.22904976e-02 -2.98280790e-02 -2.17922051e-02 -1.22581143e-03\n",
            " -1.66846551e-02 -5.58425253e-03 -1.89319775e-02 -4.42654174e-03\n",
            " -1.15090078e-02  2.11111992e-03  4.83514555e-03 -1.70455888e-01\n",
            " -3.16667967e-02  1.91362798e-02 -1.04874978e-02 -1.22581143e-02\n",
            " -2.80574635e-02 -4.41973172e-02 -1.01878554e-01 -1.13728065e-02\n",
            " -9.46598873e-03 -2.24051103e-02 -9.60900038e-02  1.00925148e-01\n",
            "  3.20072984e-03 -2.26775128e-02  8.92118365e-03  5.62511235e-02\n",
            "  1.27620593e-01  3.28245088e-02  3.24159041e-02  0.00000000e+00\n",
            "  2.11111992e-03 -3.49083871e-01 -1.34158256e-02  5.37995016e-03\n",
            " -1.37563283e-02 -1.26667190e-02  5.10754762e-03 -3.43227200e-02\n",
            "  2.13836003e-02  3.61614414e-02 -5.03944745e-03  8.41723904e-02\n",
            " -1.62079521e-02 -1.15634881e-01 -7.49107043e-04 -6.08138703e-02\n",
            " -6.27206862e-02 -5.78855444e-03 -7.42296968e-03 -2.90108714e-02\n",
            "  1.87957752e-02 -2.41076257e-02 -1.63441536e-03 -1.23943165e-02\n",
            " -3.33012119e-02 -6.26525888e-03  7.89967366e-03  3.33693102e-02\n",
            "  1.44645765e-01 -2.25413125e-02 -1.83871726e-03 -2.29499154e-02\n",
            " -3.81363556e-03 -3.56166326e-02  4.35844064e-03  6.68748245e-02\n",
            " -2.99642812e-02 -2.17241030e-02 -2.28137150e-02 -6.12905715e-04\n",
            "  6.76239282e-02 -1.42330332e-02 -2.51972359e-02 -1.43011333e-03\n",
            " -9.39107761e-02  2.51972373e-03 -7.53874034e-02  6.46956041e-02\n",
            "  5.36633022e-02  1.94086824e-02 -1.43011343e-02  4.08603810e-03\n",
            "  7.76347285e-03 -2.28818133e-02 -5.51615190e-03 -9.78606194e-02\n",
            "  1.42943248e-01  3.41184177e-02  1.56631470e-02  2.28137150e-02\n",
            " -4.38568108e-02  4.50826250e-02 -4.29034010e-02  2.17922032e-03\n",
            " -1.87276751e-02  4.29034000e-03  1.45054357e-02 -2.51972359e-02\n",
            " -2.86703687e-02 -1.30072217e-02 -8.17207620e-03 -8.10397603e-03\n",
            " -7.15056714e-03  3.24159041e-02  3.54804322e-02 -3.90216671e-02\n",
            " -4.08603839e-04 -2.22689081e-02 -5.99285634e-03  4.15413873e-03\n",
            "  2.65592476e-03  4.17456888e-02  9.26168729e-03 -7.96777476e-03\n",
            "  4.93048653e-02  4.35844064e-03  3.73872519e-02  2.52653360e-02\n",
            "  1.08961016e-03 -1.83190722e-02 -5.92475571e-03 -5.85665507e-03\n",
            " -1.11004040e-02  4.77385484e-02  2.33585183e-02  4.22904976e-02\n",
            " -4.76704491e-03  9.26168729e-03  3.16463679e-01 -1.63441536e-03\n",
            "  3.94983701e-02  2.13155001e-02 -4.83514555e-03 -8.61473009e-02\n",
            " -2.22008079e-02  2.88746692e-02 -2.26775128e-02 -3.23478021e-02\n",
            " -9.12548508e-03  3.62295397e-02 -4.08603810e-03  1.47097381e-02\n",
            "  1.72635123e-01 -2.34266203e-02  9.73839127e-03  1.71613600e-02\n",
            " -3.88854668e-02 -1.47097381e-02 -2.23370101e-02 -7.55917048e-03\n",
            "  6.81006350e-03 -1.15090078e-02 -3.00323833e-02 -1.65484548e-02\n",
            "  5.39357066e-02 -2.99642812e-02  3.99069749e-02 -8.30827747e-03\n",
            " -3.36417146e-02  1.83871726e-03  1.81147698e-02  4.08603810e-03\n",
            " -1.96810842e-01  4.78066504e-02  6.81006350e-03  4.37206104e-02\n",
            "  1.13455668e-01 -1.26667190e-02 -6.89859465e-02 -4.27672006e-02\n",
            " -7.81795308e-02 -7.18461722e-02 -9.35702771e-02  1.08280024e-02\n",
            " -1.43011343e-02  1.29391218e-03  1.28710205e-02 -1.19857127e-02\n",
            "  1.22581143e-03  7.55917048e-03  7.15056714e-03 -8.78498238e-03\n",
            "  3.13262944e-03 -7.28676841e-03  1.42126039e-01 -6.40145969e-03\n",
            "  1.97491841e-03  4.71937433e-02  2.00215876e-02 -5.31865992e-02] \n",
            "\n",
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------\n",
        "## **Embedding Alignment**\n",
        "\n",
        "We will now use the dictionary and embeddings to align the two vector spaces. The English vector space will be aligned to the German vector space using the [Procrustes](https://en.wikipedia.org/wiki/Orthogonal_Procrustes_problem) alignment method.\n",
        "\n",
        "Given two matrices, Procrustes finds an orthogonal matrix which most closely maps one input matrix to the other. As a first step, we need to compute this orthogonal transformation matrix.  \n",
        "\n"
      ],
      "metadata": {
        "id": "fZ8nhE-4LXNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Function to perform orthogonal Procrustes alignment to learn a mapping from X to Y.\n",
        "\n",
        "Parameters:\n",
        "X (numpy array): Source language word embeddings (English)\n",
        "Y (numpy array): Target language word embeddings (German)\n",
        "\n",
        "Returns:\n",
        "W (numpy array): Orthogonal transformation matrix\n",
        "\"\"\"\n",
        "def orthogonal_procrustes(X, Y):\n",
        "    X = X / np.linalg.norm(X, axis=1, keepdims=True)\n",
        "    Y = Y / np.linalg.norm(Y, axis=1, keepdims=True)\n",
        "\n",
        "    # Compute matrix product of X^T and Y\n",
        "    M = np.dot(X.T, Y)\n",
        "\n",
        "    # Perform Singular Value Decomposition (SVD) on the matrix M\n",
        "    U, _, Vt = np.linalg.svd(M)\n",
        "\n",
        "    # Compute the orthogonal transformation matrix W\n",
        "    W = np.dot(U, Vt)\n",
        "\n",
        "    return W\n",
        "\n",
        "W = orthogonal_procrustes(en_vecs, de_vecs)\n",
        "\n",
        "print(\"Orthogonal mapping matrix learned.\")\n",
        "\n",
        "print(W)\n",
        "print(len(W))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmA3RxaSg3-C",
        "outputId": "0db0d3a6-02a1-45ab-8194-7a72964c7067"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orthogonal mapping matrix learned.\n",
            "[[ 0.04907615  0.02510272 -0.10426025 ... -0.12945467  0.08390459\n",
            "   0.02807453]\n",
            " [ 0.0238353  -0.0221569  -0.00390244 ... -0.00869184  0.11116306\n",
            "  -0.0604249 ]\n",
            " [ 0.0155552   0.11592178  0.06893986 ... -0.12564601 -0.00331625\n",
            "  -0.01412949]\n",
            " ...\n",
            " [ 0.02709159 -0.03738086  0.03347469 ... -0.07060888  0.04953825\n",
            "   0.03611384]\n",
            " [ 0.2748923  -0.0502222   0.07045681 ...  0.07736033  0.01274888\n",
            "  -0.04421226]\n",
            " [-0.02611824 -0.01001144  0.10607699 ...  0.02234203 -0.03937639\n",
            "   0.01735137]]\n",
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a second step, the obtained matrix is used to learn an orthogonal mapping of the English vector space to approximate it to the German vector space. Here we can transform the entire vector space of 100,000 embeddings."
      ],
      "metadata": {
        "id": "YINE8wlfIbk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Apply the learned orthogonal mapping to the source language embeddings.\n",
        "\n",
        "Parameters:\n",
        "embeddings (dict): Source language embeddings (English)\n",
        "W (numpy array): Orthogonal transformation matrix\n",
        "\n",
        "Returns:\n",
        "mapped_embeddings (dict): Transformed embeddings\n",
        "\"\"\"\n",
        "def apply_mapping(embeddings, W):\n",
        "    mapped_embeddings = {}\n",
        "    for word, vec in embeddings.items():\n",
        "        mapped_vec = np.dot(vec, W)\n",
        "        # Normalize the mapped vector\n",
        "        mapped_vec = mapped_vec / np.linalg.norm(mapped_vec)\n",
        "        mapped_embeddings[word] = mapped_vec\n",
        "    return mapped_embeddings\n",
        "\n",
        "aligned_en_embeddings = apply_mapping(en_embeddings, W)\n",
        "\n",
        "print(f\"Aligned {len(aligned_en_embeddings)} English embeddings into the German space.\\n\")\n",
        "print(aligned_en_embeddings['good'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjogY41Vg-CC",
        "outputId": "bf8a1692-0fd4-409f-c776-7441d296fc81"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned 100000 English embeddings into the German space.\n",
            "\n",
            "[-0.02754474 -0.00419841  0.02682907 -0.08604427 -0.02118373 -0.05984071\n",
            " -0.08273644  0.04499711  0.00253932 -0.01150167  0.06392089 -0.08514164\n",
            "  0.00175307 -0.04745492 -0.00339004 -0.0455097  -0.0571388   0.00212817\n",
            "  0.10568504 -0.12549932 -0.02589734 -0.05530401 -0.02861719  0.03910202\n",
            " -0.00954981 -0.05215105  0.00966217  0.01890708 -0.04717619 -0.04405127\n",
            "  0.05568903  0.03706347 -0.07151513 -0.00591891  0.05165812  0.02123319\n",
            "  0.00586968  0.16810946  0.12827452 -0.061162   -0.06618541  0.01465025\n",
            " -0.01445273 -0.02892472 -0.02132701  0.05696031  0.03586195  0.05359138\n",
            "  0.00192775 -0.10935646  0.0332997  -0.03852529 -0.07921883 -0.01483064\n",
            "  0.10750414  0.03537637  0.0513382   0.03002121 -0.05640733 -0.11594495\n",
            " -0.01558273  0.03063875 -0.01620898 -0.00310953 -0.01153558 -0.02249036\n",
            "  0.05014528 -0.01126666  0.01947777 -0.10998777  0.1124676   0.02874888\n",
            "  0.00449159  0.01496598 -0.01910733  0.01091445 -0.0195179  -0.02378681\n",
            "  0.04830883 -0.0128493   0.06218375  0.02929305  0.05494482  0.01133952\n",
            "  0.01716254  0.14588639 -0.03949741  0.04032762  0.02729651 -0.03829109\n",
            "  0.01353867  0.14290467 -0.00589292 -0.00827084  0.03279473  0.07303219\n",
            "  0.01862381  0.0461312  -0.04582388  0.02730673  0.02313269  0.02288338\n",
            "  0.02447037  0.01337464 -0.00717597 -0.14882211  0.01649787  0.00075563\n",
            " -0.0074303   0.05856133 -0.04493804 -0.02102618 -0.02690222 -0.02693066\n",
            " -0.01484031  0.01735043  0.02719633 -0.04402684  0.06363547 -0.05506362\n",
            "  0.0498478   0.05805837  0.030266   -0.11040937  0.06721403  0.03566469\n",
            " -0.04155162  0.02876544 -0.05419957 -0.02574128  0.05299236  0.02895491\n",
            "  0.05780986 -0.052649    0.01436715  0.00089681  0.01301223  0.14730309\n",
            "  0.07819543 -0.00426615  0.03407697 -0.06648394  0.01312334  0.01256262\n",
            " -0.01370011 -0.03196436 -0.03584777  0.04937179  0.02376468  0.00660774\n",
            " -0.00340743  0.0946569  -0.03848411 -0.19290106  0.01260827 -0.18224882\n",
            "  0.03062048 -0.07323036 -0.06761751 -0.02394905  0.00509712  0.02699647\n",
            "  0.05553048  0.02227404  0.02533051  0.0109911   0.03718461 -0.00552745\n",
            "  0.14607863  0.03840956 -0.13379192 -0.08315872 -0.04751239  0.03095925\n",
            " -0.05166686 -0.06149008  0.08830361  0.01342998 -0.1728961  -0.03740536\n",
            "  0.07545029  0.05127521  0.00123311 -0.0628846  -0.07584153  0.00219353\n",
            "  0.04827206  0.05591428  0.02857958  0.02301277 -0.02426762 -0.14607406\n",
            "  0.00935041  0.04483214  0.03232435  0.08174004  0.02827018  0.01258772\n",
            " -0.01002068  0.09035633 -0.00161445 -0.0789185  -0.03649373 -0.03182045\n",
            "  0.01646069  0.01688869  0.00924027 -0.07529623  0.05704396 -0.00518182\n",
            " -0.03577164 -0.00448822  0.03182102  0.02207418  0.11332937 -0.06660099\n",
            " -0.1145287   0.05659769 -0.05009482 -0.02271839  0.0436726   0.00868184\n",
            " -0.04791417  0.00989853 -0.03534144 -0.09099901 -0.05401846 -0.01652582\n",
            " -0.05341028 -0.0186894   0.05978782  0.04310211  0.03887626  0.02350666\n",
            " -0.09626274 -0.05752802 -0.00093861  0.02229162  0.0558272   0.07423127\n",
            "  0.11743338 -0.08515266  0.03662511 -0.06335069  0.04535869 -0.02389785\n",
            " -0.01009922 -0.01514703 -0.05853065 -0.04021458  0.07242695 -0.01489406\n",
            "  0.07852285 -0.0113236   0.02782611 -0.00059777 -0.01274761  0.00184707\n",
            " -0.03794291 -0.06440514  0.0405689  -0.01844858 -0.05482944  0.05796144\n",
            "  0.02048416 -0.01024096 -0.08572049  0.00165565 -0.00339425  0.14156017\n",
            " -0.05914219 -0.03693181 -0.08983324  0.03885898  0.00031401 -0.08082587\n",
            "  0.05329774 -0.01948897  0.03283853 -0.00147262 -0.11135403 -0.01580277\n",
            " -0.01352551 -0.04158606  0.01161448 -0.05694386  0.00397886 -0.15508029\n",
            " -0.02401344 -0.00243261 -0.01943148 -0.01516839 -0.04685723 -0.0628171\n",
            "  0.10891516  0.02344982  0.09069152 -0.03291778  0.10128435 -0.03832417]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------\n",
        "## **Evaluation**\n",
        "\n",
        "In this part, you will explore two different tasks for evaluating the final vector space:\n",
        "\n",
        "\n",
        "1.   Word Translation\n",
        "2.   Cross-Lingual Analogy Completion\n",
        "\n"
      ],
      "metadata": {
        "id": "Lr2QCywEBMUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Translation\n",
        "\n",
        "We will now use the bilingual word list downloaded from MUSE to evaluate the ability of our newly created aligned embedding space to translate words from English to German.\n",
        "\n",
        "A function that takes an English word as input and ouputs the nearest neighors of the German vector space is already provided for your convenience."
      ],
      "metadata": {
        "id": "nTo8Ugi-KGAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def get_nn(word, aligned_en_embeddings, de_embeddings, top_k):\n",
        "    #print(\"Nearest neighbors of \\\"%s\\\":\" % word)\n",
        "    en_vec = aligned_en_embeddings[word]\n",
        "    de_words = list(de_embeddings.keys())\n",
        "    de_vecs = np.array(list(de_embeddings.values()))\n",
        "\n",
        "    # Compute cosine similarity between the English word vector and all German word vectors\n",
        "    en_vec = en_vec / np.linalg.norm(en_vec)\n",
        "    de_vecs_norm = de_vecs / np.linalg.norm(de_vecs, axis=1, keepdims=True)\n",
        "    similarities = cosine_similarity([en_vec], de_vecs_norm).flatten()\n",
        "\n",
        "    # Get top_k most similar German words\n",
        "    nearest_idxs = similarities.argsort()[-top_k:][::-1]\n",
        "    nearest_words = [de_words[i] for i in nearest_idxs]\n",
        "\n",
        "    return nearest_words\n",
        "\n",
        "en_word = 'the'\n",
        "nearest_neighbors = get_nn(en_word, aligned_en_embeddings, de_embeddings, 5)\n",
        "print(nearest_neighbors)"
      ],
      "metadata": {
        "id": "p63UvUddLKWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d84d2eb-aa8d-497d-f515-e47b10891886"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['der', 'die', 'den', 'dem', 'besagten']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‹ âš’ Use the already downloaded bilingual word list to evaluate the ability of our aligned vector space to translate from English to German. The output of this task should be the **accuracy** calculated on **1000 words** from the word list, i.e., how many of the first 1000 English words result in five German neighbors that correspond to the German translation from the MUSE word list.\n",
        "\n",
        "Use the provided function `get_nn` to obtain the *k* nearest words in the vector space in German, given an English input word.\n"
      ],
      "metadata": {
        "id": "zagwMc7uNqmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(en_de_pairs[3])\n",
        "print(en_de_pairs[3][0])\n",
        "print(en_de_pairs[3][1])\n",
        "print(type(en_de_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBwHxdzOt-W5",
        "outputId": "373ea8dc-94f7-4f56-95da-5fcb835af79c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('the', 'den')\n",
            "the\n",
            "den\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(aligned_en_embeddings, de_embeddings, en_de_pairs):\n",
        "    correct_count = 0\n",
        "    total_words = len(en_de_pairs)\n",
        "    for en_word, correct_translation in en_de_pairs:\n",
        "        if en_word in aligned_en_embeddings:\n",
        "          nearest_neighbors = get_nn(en_word, aligned_en_embeddings, de_embeddings, top_k=5)\n",
        "          if correct_translation in nearest_neighbors:\n",
        "            correct_count += 1\n",
        "        else:\n",
        "            continue\n",
        "    accuracy = correct_count / total_words\n",
        "    return accuracy\n",
        "\n",
        "first_1000_pairs = en_de_pairs[:1000]\n",
        "\n",
        "accuracy = calculate_accuracy(aligned_en_embeddings, de_embeddings, first_1000_pairs)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "5cvKdmP5bm4_",
        "outputId": "ba28ce41-84d6-4367-d57f-815e8606c1cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 43.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-Lingual Analogy Completion\n",
        "\n",
        "An analogy compares two related pairs of words, e.g. *man is to woman as king is to queen*. This task can be extended to use analogies for translation, e.g. *man is to woman as Mann ist zu Frau*.\n",
        "\n",
        "\n",
        "ðŸ‘‹ âš’ Create **twenty** examples of crosslingual analogies and see whether the aligned vector space is able to correctly complete analogies across languages, e.g. positive=(queen, KÃ¶nig), negative=(king). You can use examples from the analogy text file in GitHub for this purpose.\n",
        "\n",
        "Hints:\n",
        "\n",
        "\n",
        "*   Multilingual Analogies: To create the examples, all you need is a translation of an existing analogy. You can use the already loaded bilingual word list to obtain the translations and the existing analogy list (anlogies.txt on Github) to obtain analogies.\n",
        "*   Implementation: In the code below, you only need to change the embeddings to the German embeddings for `c` and provide the function with the German embeddings."
      ],
      "metadata": {
        "id": "Xj24LdO-Omrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def norm(vec):\n",
        "  return vec / np.linalg.norm(vec)\n",
        "\n",
        "def get_target_words(embeddings, vec_a, vec_b, vec_c, top_k):\n",
        "    words = list(embeddings.keys())\n",
        "    vecs = np.array(list(embeddings.values()))\n",
        "\n",
        "    # Compute analogy based on input vectors b+c-a (woman+king-man)\n",
        "    positive = norm(vec_b+vec_c)\n",
        "    target_vec = norm(positive - vec_a)\n",
        "    vecs_norm = vecs / np.linalg.norm(vecs, axis=1, keepdims=True)\n",
        "    similarities = cosine_similarity([target_vec], vecs_norm).flatten()\n",
        "\n",
        "    # Get top_k most similar words for the retrieved result vector d\n",
        "    nearest_idxs = similarities.argsort()[-top_k:][::-1]\n",
        "    nearest_words = [words[i] for i in nearest_idxs]\n",
        "\n",
        "    return nearest_words\n",
        "\n",
        "vec_a = norm(aligned_en_embeddings[\"man\"])\n",
        "vec_b = norm(aligned_en_embeddings[\"woman\"])\n",
        "vec_c = norm(aligned_en_embeddings[\"king\"])\n",
        "\n",
        "nearest_neighbors = get_target_words(aligned_en_embeddings, vec_a, vec_b, vec_c, 5)\n",
        "print(nearest_neighbors)"
      ],
      "metadata": {
        "id": "S40JvI6iOzMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32baac16-0cbe-4ae2-fe59-cbed8bce8947"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['queen', 'king', 'Queen', 'queens', 'royal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_a = norm(aligned_en_embeddings[\"man\"])\n",
        "vec_b = norm(aligned_en_embeddings[\"woman\"])\n",
        "vec_c = norm(aligned_en_embeddings[\"KÃ¶nig\"])\n",
        "\n",
        "nearest_neighbors = get_target_words(aligned_en_embeddings, vec_a, vec_b, vec_c, 5)\n",
        "print(nearest_neighbors)"
      ],
      "metadata": {
        "id": "XbUXIhM1N7ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "281a6910-d2f9-404d-a400-293de3c1f09b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['KÃ¶nig', 'Prinz', 'Birgit', 'Amalia', 'Wien']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_a = norm(aligned_en_embeddings[\"Mann\"])\n",
        "vec_b = norm(aligned_en_embeddings[\"Frau\"])\n",
        "vec_c = norm(aligned_en_embeddings[\"king\"])\n",
        "\n",
        "nearest_neighbors = get_target_words(aligned_en_embeddings, vec_a, vec_b, vec_c, 5)\n",
        "print(nearest_neighbors)"
      ],
      "metadata": {
        "id": "IhCxJ2mUPdad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43250e95-fe5f-4b19-be93-3b486ab4ba12"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['king', 'queen', 'empress', 'consort', 'princess']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it is interesting that the lowercased german words are not accepred\n",
        "vec_a = norm(aligned_en_embeddings[\"mann\"])\n",
        "vec_b = norm(aligned_en_embeddings[\"frau\"])\n",
        "vec_c = norm(aligned_en_embeddings[\"king\"])\n",
        "\n",
        "nearest_neighbors = get_target_words(aligned_en_embeddings, vec_a, vec_b, vec_c, 5)\n",
        "print(nearest_neighbors)"
      ],
      "metadata": {
        "id": "KQ1KSVwK7uCS",
        "outputId": "677c200e-1dac-42a8-ea18-031ac7528e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'mann'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c331260a186f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# it is interesting that the lowercased german words are not accepred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvec_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned_en_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mann\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvec_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned_en_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"frau\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvec_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned_en_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"king\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'mann'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading analogy file\n",
        "!wget !wget https://raw.githubusercontent.com/dgromann/cl_intro_ws2024/master/exercises/HomeExercise2.txt"
      ],
      "metadata": {
        "id": "yJy5yVv1QEXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393106ae-7c90-429e-f151-3643174d2dd3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-22 14:30:44--  http://!wget/\n",
            "Resolving !wget (!wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address â€˜!wgetâ€™\n",
            "--2025-01-22 14:30:44--  https://raw.githubusercontent.com/dgromann/cl_intro_ws2024/master/exercises/HomeExercise2.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 272272 (266K) [text/plain]\n",
            "Saving to: â€˜HomeExercise2.txtâ€™\n",
            "\n",
            "HomeExercise2.txt   100%[===================>] 265.89K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-01-22 14:30:44 (6.00 MB/s) - â€˜HomeExercise2.txtâ€™ saved [272272/272272]\n",
            "\n",
            "FINISHED --2025-01-22 14:30:44--\n",
            "Total wall clock time: 0.3s\n",
            "Downloaded: 1 files, 266K in 0.04s (6.00 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogy = open(\"HomeExercise2.txt\", 'r')\n",
        "analogy_lines = analogy.readlines()\n",
        "print(analogy_lines[:5])"
      ],
      "metadata": {
        "id": "0lqnWIwRQnqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf46ab1-1ed7-4a24-8e5c-067c2957336d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[': capital-common-countries\\n', 'Athens Greece Baghdad Iraq\\n', 'Athens Greece Berlin Germany\\n', 'Athens Greece Cairo Egypt\\n', 'Athens Greece Canberra Australia\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_analogy_lines = []\n",
        "for line in analogy_lines:\n",
        "  if ':' in line:\n",
        "    continue\n",
        "  else:\n",
        "    line = str(line).split()\n",
        "  preprocessed_analogy_lines.append(line)\n",
        "\n",
        "print(preprocessed_analogy_lines[:5])\n",
        "print(preprocessed_analogy_lines[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcF13VSXwVTz",
        "outputId": "43d005d8-c99e-4ef1-93cf-571ed8745ef8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Athens', 'Greece', 'Baghdad', 'Iraq'], ['Athens', 'Greece', 'Berlin', 'Germany'], ['Athens', 'Greece', 'Cairo', 'Egypt'], ['Athens', 'Greece', 'Canberra', 'Australia'], ['Athens', 'Greece', 'Helsinki', 'Finland']]\n",
            "Greece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check to know how to access valuesfrom the tuples\n",
        "for en_word, de_word in en_de_pairs[:5]:\n",
        "  print(en_word)\n",
        "  print(de_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJUoTfhz6I9i",
        "outputId": "25509918-9802-417f-a976-af646a3a104f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the\n",
            "die\n",
            "the\n",
            "der\n",
            "the\n",
            "dem\n",
            "the\n",
            "den\n",
            "the\n",
            "das\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analogy check for English only\n",
        "for analogy in preprocessed_analogy_lines[:20]:\n",
        "    vec_a = norm(aligned_en_embeddings[analogy[0]])\n",
        "    vec_b = norm(aligned_en_embeddings[analogy[1]])\n",
        "    vec_c = norm(aligned_en_embeddings[analogy[2]])\n",
        "    nearest_neighbors = get_target_words(aligned_en_embeddings, vec_a, vec_b, vec_c, 5)\n",
        "    print(f\"{analogy[0]} is to {analogy[1]} as {analogy[2]} is to {nearest_neighbors}\")"
      ],
      "metadata": {
        "id": "xNKoelboRW_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1721fb-e165-4203-e707-5597a91ccd0f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Athens is to Greece as Baghdad is to ['Iraq', 'Baghdad', 'Iraqis', 'Iraqi', 'Mosul']\n",
            "Athens is to Greece as Berlin is to ['Germany', 'Berlin', 'GDR', 'German', 'Deutschland']\n",
            "Athens is to Greece as Cairo is to ['Egypt', 'Cairo', 'Morocco', 'Egyptian', 'Sisi']\n",
            "Athens is to Greece as Canberra is to ['Canberra', 'Australia', 'Zealand', 'Australian', 'Australians']\n",
            "Athens is to Greece as Helsinki is to ['Finland', 'Finnish', 'Helsinki', 'Scandinavia', 'Sweden']\n",
            "Athens is to Greece as London is to ['England', 'London', 'U.K', 'Britain', 'U.K.']\n",
            "Athens is to Greece as Madrid is to ['Spain', 'Madrid', 'Portugal', 'Ronaldo', 'Benzema']\n",
            "Athens is to Greece as Moscow is to ['Russia', 'Russian', 'Ukraine', 'Kremlin', 'Moscow']\n",
            "Athens is to Greece as Ottawa is to ['Canada', 'Ottawa', 'Quebec', 'Canadians', 'Ontario']\n",
            "Athens is to Greece as Paris is to ['France', 'Paris', 'Parisian', 'Hollande', 'Sarkozy']\n",
            "Athens is to Greece as Rome is to ['Italy', 'Vatican', 'papacy', 'Papacy', 'pontiff']\n",
            "Athens is to Greece as Stockholm is to ['Sweden', 'Norway', 'Scandinavia', 'Stockholm', 'Swedish']\n",
            "Athens is to Greece as Tehran is to ['Iran', 'Tehran', 'Iranian', 'Iranians', 'mullahs']\n",
            "Athens is to Greece as Tokyo is to ['Japan', 'Tokyo', 'Japanese', 'Hokkaido', 'Kansai']\n",
            "Baghdad is to Iraq as Berlin is to ['Germany', 'Berlin', 'GDR', 'Deutschland', 'Weimar']\n",
            "Baghdad is to Iraq as Cairo is to ['Egypt', 'Cairo', 'egypt', 'Egyptian', 'Sudan']\n",
            "Baghdad is to Iraq as Canberra is to ['Canberra', 'Australia', 'Zealand', 'Qld', 'NSW']\n",
            "Baghdad is to Iraq as Helsinki is to ['Finland', 'Helsinki', 'Finnish', 'Sweden', 'Tampere']\n",
            "Baghdad is to Iraq as London is to ['London', 'England', 'Britain', 'U.K', 'UK']\n",
            "Baghdad is to Iraq as Madrid is to ['Madrid', 'Spain', 'Catalonia', 'Barca', 'Barcelona']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nearest_neighbors_list  = []\n",
        "for analogy in preprocessed_analogy_lines:\n",
        "  vec_a = norm(aligned_en_embeddings[analogy[0]])\n",
        "  vec_b = norm(aligned_en_embeddings[analogy[1]])\n",
        "  for en_word, de_word in en_de_pairs:\n",
        "    de_word = str(de_word.capitalize())\n",
        "    if en_word == analogy[2] and de_word in aligned_en_embeddings:\n",
        "      vec_c = norm(aligned_en_embeddings[de_word])\n",
        "      nearest_neighbors = get_target_words(aligned_en_embeddings, vec_a, vec_b, vec_c, 5)\n",
        "      nearest_neighbors_list.append(nearest_neighbors)\n",
        "      print(f\"{analogy[0]} is to {analogy[1]} as {de_word} is to {nearest_neighbors}\")\n",
        "    if len(nearest_neighbors_list) == 20:\n",
        "      break\n",
        "    else:\n",
        "      continue"
      ],
      "metadata": {
        "id": "ROtuZyyOdTXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529836f0-91c9-498b-a22b-6e7c989d3e75"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "boy is to girl as Brothers is to ['Brothers', 'Sisters', 'Bros', 'Bros.', 'Associates']\n",
            "boy is to girl as Dad is to ['Mom', 'Dad', 'Mum', 'Grandma', 'Husband']\n",
            "boy is to girl as Papa is to ['Papa', 'Mama', 'Nana', 'Mamma', 'Caffe']\n",
            "boy is to girl as Seine is to ['Seine', 'Loire', 'Meuse', 'Moselle', 'Montmartre']\n",
            "boy is to girl as Sein is to ['Sein', 'Aung', 'Kyi', 'Frau', 'Zeit']\n",
            "boy is to girl as Mann is to ['Mann', 'Whitney', 'Weil', 'McIntyre', 'Kerr']\n",
            "boy is to girl as King is to ['King', 'Queen', 'Empress', 'Kings', 'Crown']\n",
            "boy is to girl as KÃ¶nig is to ['KÃ¶nig', 'Prinz', 'MÃ¼ller', 'Bernhard', 'Graf']\n",
            "boy is to girl as Mann is to ['Mann', 'Whitney', 'Weil', 'McIntyre', 'Kerr']\n",
            "boy is to girl as Man is to ['Woman', 'Man', 'Girl', 'Bitch', 'Lover']\n",
            "boy is to girl as Sohn is to ['Sohn', 'Ahn', 'Hwang', 'Chairwoman', 'Blume']\n",
            "boy is to girl as Sons is to ['Sons', 'Daughters', 'Girlfriends', 'Brides', 'Sisters']\n",
            "brother is to sister as Brothers is to ['Sisters', 'Brothers', 'Bros', 'Bros.', 'Boutique']\n",
            "brother is to sister as Dad is to ['Mom', 'Mum', 'Dad', 'Mommy', 'Mums']\n",
            "brother is to sister as Papa is to ['Papa', 'Mama', 'Mamma', 'Momma', 'Nana']\n",
            "brother is to sister as Seine is to ['Seine', 'Loire', 'Meuse', 'Moselle', 'Danube']\n",
            "brother is to sister as Sein is to ['Sein', 'Zeit', 'Frau', 'Und', 'Liebe']\n",
            "brother is to sister as Mann is to ['Mann', 'Weil', 'McIntyre', 'Whitney', 'Wald']\n",
            "brother is to sister as King is to ['King', 'Queen', 'Kings', 'Princess', 'Queens']\n",
            "brother is to sister as KÃ¶nig is to ['KÃ¶nig', 'Prinz', 'NÃ¼rnberg', 'Wien', 'Frau']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Another Language Pair\n",
        "\n",
        "I have chosen Spanish and Italian, since they have been provided in dictionaries by MUSE project.\n",
        "\n",
        "P.s. I am currently learning Italian and I have never learnt Spanish, however I want to try to allign these languages and see their similarities."
      ],
      "metadata": {
        "id": "e8r-zloOiHTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz  # Spanish\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.vec.gz  # Italian"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3ufz2yTkeGp",
        "outputId": "50f0d26c-0494-40c3-c511-f7ab6f328f95"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-22 14:36:05--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.171.22.68, 3.171.22.33, 3.171.22.13, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.171.22.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1285580896 (1.2G) [binary/octet-stream]\n",
            "Saving to: â€˜cc.es.300.vec.gzâ€™\n",
            "\n",
            "cc.es.300.vec.gz    100%[===================>]   1.20G   108MB/s    in 19s     \n",
            "\n",
            "2025-01-22 14:36:24 (65.6 MB/s) - â€˜cc.es.300.vec.gzâ€™ saved [1285580896/1285580896]\n",
            "\n",
            "--2025-01-22 14:36:24--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.171.22.68, 3.171.22.33, 3.171.22.13, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.171.22.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1272825284 (1.2G) [binary/octet-stream]\n",
            "Saving to: â€˜cc.it.300.vec.gzâ€™\n",
            "\n",
            "cc.it.300.vec.gz    100%[===================>]   1.18G  33.8MB/s    in 36s     \n",
            "\n",
            "2025-01-22 14:37:01 (33.9 MB/s) - â€˜cc.it.300.vec.gzâ€™ saved [1272825284/1272825284]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es_embeddings = load_fasttext_embeddings('cc.es.300.vec.gz', 100000)\n",
        "it_embeddings = load_fasttext_embeddings('cc.it.300.vec.gz', 100000)\n",
        "\n",
        "print(f\"Loaded {len(de_embeddings)} German embeddings\")\n",
        "print(f\"Loaded {len(it_embeddings)} Italian embeddings\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0XWHeMZknfX",
        "outputId": "cef0d3c7-6396-4260-b1f6-50d68936b5f2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 100000 German embeddings\n",
            "Loaded 100000 Italian embeddings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/arrival/dictionaries/es-it.0-5000.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSAyF12lkNOY",
        "outputId": "699d5c7d-a1ad-412e-976c-452961a00478"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-22 15:06:34--  https://dl.fbaipublicfiles.com/arrival/dictionaries/es-it.0-5000.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.167.112.66, 3.167.112.53, 3.167.112.51, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.167.112.66|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87009 (85K) [text/plain]\n",
            "Saving to: â€˜es-it.0-5000.txtâ€™\n",
            "\n",
            "es-it.0-5000.txt    100%[===================>]  84.97K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-01-22 15:06:35 (659 KB/s) - â€˜es-it.0-5000.txtâ€™ saved [87009/87009]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_bilingual_word_list_es_it(file_path):\n",
        "    bilingual_dict = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "      for line in f:\n",
        "          tokens = str(line).strip().split('\\t')\n",
        "          es_word = tokens[0]\n",
        "          it_word = tokens[1]\n",
        "          word_pair = (es_word, it_word)\n",
        "          bilingual_dict.append(word_pair)\n",
        "    return bilingual_dict\n",
        "\n",
        "# the deliminator in the dictionary was different ('\\t'), so I changed a little the function\n",
        "\n",
        "es_it_pairs = load_bilingual_word_list_es_it('es-it.0-5000.txt')\n",
        "\n",
        "print(es_it_pairs[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik1jvwffiLGx",
        "outputId": "65299722-a9fc-49e4-f062-af0bbb29bfd1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('que', 'che'), ('del', 'del'), ('los', 'gli'), ('con', 'con'), ('las', 'le'), ('una', 'una'), ('categorÃ­a', 'categoria'), ('para', 'per'), ('como', 'come'), ('fue', 'fu')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es_vecs, it_vecs = extract_word_embeddings(es_it_pairs, es_embeddings, it_embeddings)\n",
        "\n",
        "print(f\"Extracted {es_vecs.shape[0]} aligned word vectors in Spanish.\")\n",
        "print(f\"Extracted {it_vecs.shape[0]} aligned word vectors in Italian.\\n\")\n",
        "\n",
        "print(en_vecs[0],\"\\n\")\n",
        "print(len(en_vecs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hBwjc3zo3s-",
        "outputId": "25dcacac-76a4-41aa-c80d-35c3ef4b6963"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 4559 aligned word vectors in Spanish.\n",
            "Extracted 4559 aligned word vectors in Italian.\n",
            "\n",
            "[-4.08684798e-02  5.84964715e-02 -1.03554558e-02  3.53350304e-02\n",
            " -2.71139033e-02  1.67584475e-02  5.45440055e-03 -1.28850332e-02\n",
            " -1.43079208e-02 -1.58098573e-03 -8.07093158e-02  4.66390792e-03\n",
            "  2.03156658e-02 -2.05528131e-03 -4.63228822e-02 -2.98806280e-02\n",
            "  1.28850332e-02  1.15411952e-02 -6.95633702e-03 -1.39126740e-02\n",
            " -6.71918970e-03 -6.16584392e-03 -1.44660193e-02  6.95633702e-03\n",
            "  1.02764065e-03 -7.41482303e-02  1.09878499e-02  1.17783435e-02\n",
            " -3.11454181e-02 -2.32404899e-02  7.43063260e-03 -1.99204199e-02\n",
            " -8.22112523e-03 -1.74936071e-01 -1.81022864e-02 -7.03538628e-03\n",
            " -2.54538711e-02  6.49785101e-02  1.66003488e-03  2.22918987e-02\n",
            "  5.69154834e-03 -7.19348527e-03 -2.78253481e-02 -1.40707726e-02\n",
            " -5.58087975e-02  4.98010479e-02 -7.27253407e-03 -1.76279899e-02\n",
            " -4.42675967e-03  4.07103822e-02 -2.42681298e-02  3.44654880e-02\n",
            " -8.69542081e-03 -4.38723527e-02  7.03538628e-03 -5.32001667e-02\n",
            "  8.30017496e-03  4.53742892e-02  7.82587938e-03 -2.23709475e-02\n",
            "  3.71531621e-02  4.18961188e-03  2.37147859e-03  5.53344958e-04\n",
            "  3.50188352e-02  5.45440055e-03 -2.64024604e-02  7.19348527e-03\n",
            " -6.00774586e-03  5.21725276e-03  7.24881962e-02  2.45843269e-02\n",
            "  4.29237597e-02  2.22918987e-02 -1.58098564e-02 -2.64024604e-02\n",
            "  4.18961188e-03  2.87739411e-02  1.77781850e-01  7.33577311e-02\n",
            " -9.72306170e-03  6.79823849e-03 -4.73505221e-02  5.34373149e-02\n",
            "  3.17778103e-02  9.48591449e-04  3.66788656e-02 -3.45445350e-02\n",
            "  4.66390792e-03  7.24881962e-02 -3.25683057e-02 -1.19364420e-02\n",
            " -1.82603840e-02  7.50968186e-03  4.64809798e-02  2.20547486e-02\n",
            "  5.11448868e-02 -4.48999926e-02 -1.02764070e-02  3.74693610e-02\n",
            "  2.79834457e-02 -9.56496317e-03 -6.08679466e-03 -1.03238367e-01\n",
            "  1.05926041e-02 -3.99989374e-02  8.77447054e-03  9.40686464e-03\n",
            " -1.74698923e-02  3.11454181e-02  1.74698923e-02  1.93670746e-02\n",
            "  3.08292196e-03  9.05904844e-02  1.80232376e-02 -3.69950645e-02\n",
            " -3.62836197e-02 -1.49403140e-02  6.00774586e-03 -2.38728840e-02\n",
            " -2.75091510e-02 -2.28452422e-02 -3.15406658e-02  1.93670746e-02\n",
            " -8.06302764e-03  4.56904843e-02 -3.06711234e-02 -9.24876612e-03\n",
            " -2.40309834e-02  1.94935530e-01 -8.77447054e-03  2.81415451e-02\n",
            "  3.63626704e-03  1.65529191e-01 -8.07883665e-02  2.65605580e-02\n",
            "  5.43859079e-02 -5.59668913e-02  2.12642588e-02 -3.34378481e-02\n",
            "  6.08679466e-03 -2.11061575e-02  5.69154834e-03  2.76672491e-03\n",
            "  2.77462993e-02 -4.98010498e-03 -3.52717906e-01  8.30017496e-03\n",
            " -9.48591437e-03 -3.54931280e-02 -1.34067580e-01  3.98408398e-02\n",
            "  7.35158324e-02 -3.47816851e-03 -3.24102072e-03  2.54538711e-02\n",
            "  1.60153851e-01  4.84572090e-02 -2.33195387e-02  1.80232376e-02\n",
            " -1.50193637e-02  1.36755267e-02  1.16992943e-01 -1.38336243e-02\n",
            " -9.88116022e-03  5.43068573e-02  2.63234116e-02 -2.39519328e-02\n",
            "  3.38330939e-02  4.03151382e-03  1.80232376e-02  8.22112523e-03\n",
            "  5.77850267e-02  6.24489319e-03 -4.03151382e-03  4.29237597e-02\n",
            " -2.56910156e-02  4.04732339e-02  2.27661934e-02 -4.63228822e-02\n",
            " -0.00000000e+00  3.89712974e-02  1.31221805e-02 -1.13040479e-02\n",
            "  2.83786934e-02  4.29237597e-02 -3.95246432e-04 -4.65600267e-02\n",
            "  1.28059844e-02 -1.75489411e-02 -1.57308076e-02  1.85765810e-02\n",
            " -5.35954162e-02  1.41498214e-02  2.60862638e-03  9.01161879e-03\n",
            "  3.73903103e-02 -3.50188352e-02  2.55329181e-02  1.54146105e-02\n",
            " -5.11448868e-02  2.67818987e-01  5.52554466e-02 -1.69955958e-02\n",
            " -1.92880239e-02 -2.68767565e-03 -2.68767565e-03 -4.91686538e-02\n",
            "  9.72306170e-03  2.96434816e-02 -1.55727090e-02  1.90508775e-02\n",
            " -6.93262219e-02  1.58889052e-02 -4.82200598e-03 -2.02366170e-02\n",
            " -1.50984125e-02 -2.08690111e-02  1.50193637e-02 -3.33587974e-02\n",
            "  1.98413711e-02  6.52156621e-02 -7.58873159e-03  1.01815484e-01\n",
            "  4.90896069e-02  4.25285175e-02  1.49403140e-02  3.33587974e-02\n",
            "  1.42525852e-01 -7.90492864e-04 -2.59281658e-02 -4.41885479e-02\n",
            " -1.24107366e-02  3.87341492e-02  2.78253481e-02 -3.29635516e-02\n",
            "  1.25688370e-02 -6.05517514e-02 -5.19353822e-02  3.92874926e-02\n",
            "  8.06302764e-03  1.16281494e-01 -5.62040396e-02 -1.16123393e-01\n",
            "  3.74456435e-01 -1.33593287e-02 -4.03151382e-03  1.25688370e-02\n",
            "  4.34771068e-02 -5.01172468e-02 -1.66003499e-02  9.64401197e-03\n",
            "  2.12642588e-02  4.74295719e-03  5.24887219e-02  8.37922376e-03\n",
            " -5.57297468e-02 -1.63632017e-02 -6.19746372e-02 -2.30033416e-02\n",
            " -2.23709475e-02 -1.23949274e-01 -3.10663674e-02  3.95246409e-03\n",
            "  1.61260553e-02 -2.05528131e-03  3.44654880e-02  2.20547486e-02\n",
            " -3.10663674e-02  2.90110856e-02 -3.32006975e-03 -1.23316878e-02\n",
            " -5.79431206e-02 -1.29403681e-01  5.15401326e-02 -4.90105571e-03\n",
            " -5.13820313e-02 -1.56833783e-01 -3.24892551e-02 -1.21261604e-01\n",
            "  1.58098573e-03  1.05135543e-02 -1.86872497e-01 -4.17380221e-02\n",
            " -3.32006975e-03 -3.53350304e-02  8.85351934e-03 -2.62443610e-02\n",
            " -4.34771068e-02  1.02764065e-03  1.33593287e-02 -3.47026363e-02\n",
            " -4.56904843e-02  1.76279899e-02 -6.14212900e-02 -3.41492929e-02\n",
            " -1.98413711e-02  1.87346801e-01  3.16197140e-04 -3.32006975e-03] \n",
            "\n",
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = orthogonal_procrustes(es_vecs, it_vecs)\n",
        "\n",
        "print(\"Orthogonal mapping matrix learned.\")\n",
        "\n",
        "print(W)\n",
        "print(len(W))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGarLSR1plsY",
        "outputId": "902b1427-9532-4430-877b-0ae2da21a516"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orthogonal mapping matrix learned.\n",
            "[[ 0.00455346  0.07381329  0.02808644 ...  0.0875571  -0.038165\n",
            "   0.02927761]\n",
            " [-0.04569927  0.07067674  0.01982277 ... -0.08923655 -0.05170725\n",
            "  -0.02111657]\n",
            " [ 0.00264618  0.0182407   0.06173337 ...  0.06884508 -0.02480747\n",
            "   0.03904527]\n",
            " ...\n",
            " [ 0.00861881  0.09381516  0.00848095 ... -0.03586415  0.0121546\n",
            "  -0.05274847]\n",
            " [ 0.06531589 -0.01833704 -0.00022117 ... -0.08379734 -0.01936114\n",
            "   0.055649  ]\n",
            " [ 0.02092096 -0.01288716  0.03741272 ...  0.00573095  0.06037452\n",
            "  -0.0322739 ]]\n",
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aligned_es_embeddings = apply_mapping(es_embeddings, W)\n",
        "\n",
        "print(f\"Aligned {len(aligned_es_embeddings)} Spanish embeddings into the Italian space.\\n\")\n",
        "print(aligned_es_embeddings['que'])\n",
        "print(len(aligned_es_embeddings['que']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIX2W4FCppNY",
        "outputId": "e55016b1-a6f1-4133-ef3f-6d4e9dda660c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned 100000 Spanish embeddings into the Italian space.\n",
            "\n",
            "[ 8.65251385e-03 -6.30816817e-02 -7.19834119e-02 -1.57016739e-02\n",
            "  1.87086724e-02 -3.86627987e-02 -1.98480673e-04 -1.18170762e-02\n",
            " -7.03878626e-02 -3.49873491e-02 -1.13263670e-02 -3.20260115e-02\n",
            "  4.04466279e-02  5.63899167e-02  1.57423429e-02  2.25290563e-02\n",
            "  1.27524678e-02 -2.09221663e-03  3.59075442e-02 -1.23399310e-04\n",
            "  3.23215723e-02 -1.38323512e-02 -1.98801104e-02  2.69710496e-02\n",
            "  2.57578529e-02  3.06262970e-02 -5.63047975e-02  1.08472211e-03\n",
            "  4.57612276e-02 -1.08298048e-01  1.18853739e-02 -1.05023548e-01\n",
            "  5.10125794e-02  2.77649276e-02 -5.94361722e-02  2.92340666e-02\n",
            "  3.03509720e-02 -4.09239158e-02  2.63330359e-02  2.19540261e-02\n",
            "  3.49285826e-02 -1.33261038e-02 -1.55799249e-02 -8.30226112e-04\n",
            " -5.41507676e-02  6.02692515e-02 -4.13471870e-02  4.14201915e-02\n",
            "  8.74046143e-03  6.57625124e-02  2.57003140e-02 -2.51871049e-02\n",
            " -1.10416883e-03  3.52083594e-02  5.86096048e-02 -5.64280823e-02\n",
            " -3.66517645e-03  7.22173676e-02 -8.36283118e-02 -4.30987477e-02\n",
            "  2.94466726e-02 -9.85477194e-02 -1.70867331e-02 -1.22885555e-02\n",
            " -5.72119355e-02  8.84704590e-02 -2.11783927e-02 -3.25294808e-02\n",
            " -3.71879339e-02  8.23034532e-03 -3.60949477e-03 -1.62822716e-02\n",
            "  6.99505350e-03  1.57573726e-04 -1.02300448e-02 -6.13117851e-02\n",
            " -3.35112363e-02 -2.11677738e-02  3.61223780e-02  8.33827816e-03\n",
            "  4.77766916e-02 -3.06914747e-02 -5.39514497e-02  1.73854809e-02\n",
            " -7.30480850e-02  1.53588176e-01 -3.15134749e-02 -1.45720672e-02\n",
            "  2.17910800e-02  2.20352970e-02 -5.55081889e-02  2.66638771e-02\n",
            " -7.34873340e-02  6.07738160e-02 -2.36732364e-01 -1.68983433e-02\n",
            "  4.75571938e-02  2.75174789e-02  1.69806316e-01  6.12399913e-03\n",
            " -1.63752809e-02 -4.42781076e-02 -7.77976681e-03  6.04807325e-02\n",
            " -8.96203443e-02  4.88981195e-02  5.09195495e-03  6.70908438e-03\n",
            "  7.69498339e-03 -2.28715595e-02 -3.18625104e-03 -1.00641709e-03\n",
            "  1.32009923e-01 -3.13673029e-03 -7.65866973e-03  1.58321089e-03\n",
            "  2.60052830e-03  1.25896046e-02 -5.43912686e-03 -2.91570574e-02\n",
            "  1.79732814e-02  2.69097015e-02 -1.74406897e-02  4.75709885e-03\n",
            "  8.01570900e-03  4.61389869e-02  4.68896143e-03  2.23330595e-02\n",
            "  2.00054739e-02  3.25451195e-01 -7.44197285e-03  3.36166397e-02\n",
            "  3.18862535e-02  7.25714117e-02  2.23396756e-02  1.60902441e-02\n",
            "  1.45667326e-03  6.68019801e-02 -2.10686587e-02  5.14150690e-03\n",
            "  8.50003585e-03 -4.11661789e-02  2.66388841e-02 -1.34396402e-03\n",
            "  7.54569471e-03  5.87862823e-03 -5.55203445e-02 -9.37446058e-02\n",
            " -3.62487435e-02  7.49920607e-02 -1.11965863e-02 -4.61976118e-02\n",
            " -7.41448998e-02 -3.43000926e-02  6.41775951e-02 -2.64831465e-02\n",
            "  7.32310638e-02 -1.34293333e-01  1.55659262e-02  3.06575224e-02\n",
            " -4.11875732e-02  4.27821614e-02 -6.79613724e-02 -3.09058353e-02\n",
            "  1.81657597e-02 -1.44742206e-02  2.38476079e-02  6.58212826e-02\n",
            " -8.95887706e-03  8.17045569e-03 -3.93343754e-02 -4.16521803e-02\n",
            "  1.99209169e-01  6.20029010e-02 -5.97839169e-02 -5.82819805e-02\n",
            " -2.38912944e-02  4.39119451e-02 -1.97404474e-02 -2.86815874e-03\n",
            "  2.49475576e-02  2.06041690e-02 -9.62107815e-03 -3.99441877e-03\n",
            " -8.45321342e-02  2.19415706e-02  4.00961265e-02 -1.49652557e-02\n",
            "  8.36508232e-04  3.32675017e-02  4.14984338e-02  9.72697884e-03\n",
            "  6.93172440e-02  1.50470912e-01  5.52098528e-02 -4.03365120e-02\n",
            " -9.43392888e-02 -1.01067815e-02 -5.75444624e-02  1.91789009e-02\n",
            "  9.32603981e-03  1.95599943e-02  2.45317407e-02 -3.35632153e-02\n",
            " -4.63245017e-03 -1.67193217e-03 -4.16853800e-02  4.56257388e-02\n",
            " -3.91213223e-04 -1.31277934e-01  1.94229521e-02 -9.11953393e-03\n",
            "  1.51821868e-02 -2.87769344e-02  1.20608630e-02  2.70393658e-02\n",
            " -5.71377054e-02  2.66620610e-02 -7.43566826e-03  3.65799479e-02\n",
            " -3.44427302e-04  9.61446017e-02 -1.04983717e-01  2.07624696e-02\n",
            " -1.82463247e-02  3.04146446e-02  3.86819132e-02  2.71829903e-01\n",
            "  2.99642030e-02 -1.25267450e-02 -1.27825150e-02 -1.15185723e-01\n",
            " -3.39976028e-02 -2.85665374e-02 -2.19082758e-02  3.83955352e-02\n",
            " -3.35716978e-02  5.35776019e-02 -1.11660687e-02 -6.10961951e-03\n",
            " -5.35039268e-02 -1.32009704e-02 -1.92102902e-02 -8.63965377e-02\n",
            "  3.85793927e-03  9.73598808e-02 -1.86997708e-02  3.52705568e-02\n",
            "  1.85630340e-02 -1.08201861e-01  1.99976154e-02 -5.15132658e-02\n",
            "  1.78816300e-02 -6.03996264e-03  3.62498835e-02 -8.69629253e-03\n",
            " -3.10763624e-02 -5.77445067e-02 -1.02702856e-01  3.08539160e-02\n",
            "  2.73220837e-02  2.83439141e-02 -1.18526906e-01 -3.01809125e-02\n",
            " -6.89728232e-03  3.93872149e-02 -7.46835768e-03 -4.59625758e-02\n",
            "  3.38648036e-02 -1.76829379e-02 -4.43410575e-02 -1.26891593e-02\n",
            "  5.16782328e-02 -3.68245728e-02  1.08598754e-01 -4.85646352e-02\n",
            " -4.36759293e-02 -7.66519606e-02 -1.10847421e-01  5.76479919e-02\n",
            " -2.76083589e-01  2.78264917e-02 -1.60345621e-02  1.74652841e-02\n",
            " -1.66250374e-02  4.54464592e-02 -8.61193687e-02  6.38014451e-02\n",
            " -6.15976676e-02 -2.96930410e-02 -3.24026160e-02  1.31361838e-02\n",
            "  2.14312528e-03 -9.27541964e-03 -2.72184908e-02  6.77172933e-03\n",
            "  6.85305474e-03 -4.92694005e-02 -1.40454853e-02  1.08621502e-03]\n",
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding nearest neighbors\n",
        "es_word = 'que'\n",
        "nearest_neighbors = get_nn(es_word, aligned_es_embeddings, it_embeddings, 5)\n",
        "print(nearest_neighbors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9_UjlRzsCd-",
        "outputId": "21c75b81-6b1a-4040-acf7-e72b70a093b2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['che', 'invece', 'non', 'perÃ²', 'perchÃ©']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "it_word = 'donna'\n",
        "nearest_neighbors = get_nn(it_word, aligned_es_embeddings, it_embeddings, 5)\n",
        "print(nearest_neighbors)"
      ],
      "metadata": {
        "id": "RWApAHPBs7qW",
        "outputId": "7a147d6b-9bd7-471a-c18b-05e0fb1f23d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['regina', 'perfida', 'bionda', 'Callas', 'femme']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating accuracy\n",
        "first_es_it_1000_pairs = es_it_pairs[:1000]\n",
        "\n",
        "accuracy = calculate_accuracy(aligned_es_embeddings, it_embeddings, first_es_it_1000_pairs)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGzyogo_bWLL",
        "outputId": "c7ceee18-2468-4be8-bbbd-672e27026245"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 88.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analogy test\n",
        "vec_a = norm(aligned_es_embeddings[\"hombre\"])\n",
        "vec_b = norm(aligned_es_embeddings[\"mujer\"])\n",
        "vec_c = norm(aligned_es_embeddings[\"rey\"])\n",
        "\n",
        "nearest_neighbors = get_target_words(aligned_es_embeddings, vec_a, vec_b, vec_c, 5)\n",
        "print(nearest_neighbors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK4BSmGloj_v",
        "outputId": "3e03c372-f3ec-4952-c73c-119efd40a7a5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['reina', 'rey', 'princesa', 'emperatriz', 'Reina']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analogy test\n",
        "vec_a = norm(aligned_es_embeddings[\"hombre\"])\n",
        "vec_b = norm(aligned_es_embeddings[\"mujer\"])\n",
        "vec_c = norm(aligned_es_embeddings[\"re\"]) # king auf Italian\n",
        "\n",
        "nearest_neighbors = get_target_words(aligned_es_embeddings, vec_a, vec_b, vec_c, 5)\n",
        "print(nearest_neighbors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb_ViAX4qz7P",
        "outputId": "4fb64544-27a4-489d-8dd3-d0279f09e1ca"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['re', 'ta', 'so', 'Ã±a', 'We']\n"
          ]
        }
      ]
    }
  ]
}